{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50cc314e",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 구현\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a10140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x295e6dbaf70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a058593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "X_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "X_train = torch.FloatTensor(X_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9687a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.zeros((2, 1), requires_grad= True)\n",
    "b = torch.zeros(1, requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7491382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "h = 1 / (1 + torch.exp(-(X_train.matmul(w) + b)))\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb3e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<MulBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print(h)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cb34b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6931], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하나의 원소에 대한 오차\n",
    "-(y_train[0] * torch.log(h[0])) + (1 - y_train[0]) * torch.log(1 - h[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52419700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931],\n",
      "        [0.6931]], grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 모든 원소에 대한 오차\n",
    "losses = -(y_train * torch.log(h) + (1-y_train) * torch.log(1 - h))\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc60b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = losses.mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26cb7b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀의 비용함수\n",
    "F.binary_cross_entropy(h, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c83baaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(X_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f102e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.693147\n",
      "Epoch  100/1000 Cost: 0.134722\n",
      "Epoch  200/1000 Cost: 0.080643\n",
      "Epoch  300/1000 Cost: 0.057900\n",
      "Epoch  400/1000 Cost: 0.045300\n",
      "Epoch  500/1000 Cost: 0.037261\n",
      "Epoch  600/1000 Cost: 0.031673\n",
      "Epoch  700/1000 Cost: 0.027556\n",
      "Epoch  800/1000 Cost: 0.024394\n",
      "Epoch  900/1000 Cost: 0.021888\n",
      "Epoch 1000/1000 Cost: 0.019852\n"
     ]
    }
   ],
   "source": [
    "w = torch.zeros((2,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([w,b], lr=1)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs + 1) :\n",
    "    h = torch.sigmoid(X_train.matmul(w) + b)\n",
    "    cost = -(y_train * torch.log(h) + (1- y_train) * torch.log(1- h)).mean() \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, epochs, cost.item()\n",
    "        ))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dda7828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7648e-04],\n",
      "        [3.1608e-02],\n",
      "        [3.8977e-02],\n",
      "        [9.5622e-01],\n",
      "        [9.9823e-01],\n",
      "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "h = torch.sigmoid(X_train.matmul(w) + b)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54f8e431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True]])\n"
     ]
    }
   ],
   "source": [
    "pred = h >= torch.FloatTensor([0.5])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c10df9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2530],\n",
      "        [1.5179]], requires_grad=True) tensor([-14.4819], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c09c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aeee105",
   "metadata": {},
   "source": [
    "# nn.Module로 로지스틱 회귀 구현\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2da5f736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x295e6dbaf70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac1351a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "X_train = torch.FloatTensor(X_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86518c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential( # module 층 쌓기\n",
    "    nn.Linear(2, 1),\n",
    "    nn.Sigmoid()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "692c72f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5427],\n",
       "        [0.6331],\n",
       "        [0.4456],\n",
       "        [0.6306],\n",
       "        [0.6294],\n",
       "        [0.5362]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0d875ef",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost : 0.653724 Acc 66.67%\n",
      "Epoch   10/1000 Cost : 0.357625 Acc 83.33%\n",
      "Epoch   20/1000 Cost : 0.428173 Acc 83.33%\n",
      "Epoch   30/1000 Cost : 0.340048 Acc 83.33%\n",
      "Epoch   40/1000 Cost : 0.286195 Acc 83.33%\n",
      "Epoch   50/1000 Cost : 0.238611 Acc 100.00%\n",
      "Epoch   60/1000 Cost : 0.196563 Acc 100.00%\n",
      "Epoch   70/1000 Cost : 0.165590 Acc 100.00%\n",
      "Epoch   80/1000 Cost : 0.148768 Acc 100.00%\n",
      "Epoch   90/1000 Cost : 0.138111 Acc 100.00%\n",
      "Epoch  100/1000 Cost : 0.129119 Acc 100.00%\n",
      "Epoch  110/1000 Cost : 0.121249 Acc 100.00%\n",
      "Epoch  120/1000 Cost : 0.114300 Acc 100.00%\n",
      "Epoch  130/1000 Cost : 0.108120 Acc 100.00%\n",
      "Epoch  140/1000 Cost : 0.102588 Acc 100.00%\n",
      "Epoch  150/1000 Cost : 0.097606 Acc 100.00%\n",
      "Epoch  160/1000 Cost : 0.093097 Acc 100.00%\n",
      "Epoch  170/1000 Cost : 0.088996 Acc 100.00%\n",
      "Epoch  180/1000 Cost : 0.085250 Acc 100.00%\n",
      "Epoch  190/1000 Cost : 0.081814 Acc 100.00%\n",
      "Epoch  200/1000 Cost : 0.078651 Acc 100.00%\n",
      "Epoch  210/1000 Cost : 0.075730 Acc 100.00%\n",
      "Epoch  220/1000 Cost : 0.073023 Acc 100.00%\n",
      "Epoch  230/1000 Cost : 0.070507 Acc 100.00%\n",
      "Epoch  240/1000 Cost : 0.068164 Acc 100.00%\n",
      "Epoch  250/1000 Cost : 0.065975 Acc 100.00%\n",
      "Epoch  260/1000 Cost : 0.063925 Acc 100.00%\n",
      "Epoch  270/1000 Cost : 0.062002 Acc 100.00%\n",
      "Epoch  280/1000 Cost : 0.060194 Acc 100.00%\n",
      "Epoch  290/1000 Cost : 0.058491 Acc 100.00%\n",
      "Epoch  300/1000 Cost : 0.056883 Acc 100.00%\n",
      "Epoch  310/1000 Cost : 0.055364 Acc 100.00%\n",
      "Epoch  320/1000 Cost : 0.053925 Acc 100.00%\n",
      "Epoch  330/1000 Cost : 0.052561 Acc 100.00%\n",
      "Epoch  340/1000 Cost : 0.051266 Acc 100.00%\n",
      "Epoch  350/1000 Cost : 0.050034 Acc 100.00%\n",
      "Epoch  360/1000 Cost : 0.048861 Acc 100.00%\n",
      "Epoch  370/1000 Cost : 0.047743 Acc 100.00%\n",
      "Epoch  380/1000 Cost : 0.046676 Acc 100.00%\n",
      "Epoch  390/1000 Cost : 0.045656 Acc 100.00%\n",
      "Epoch  400/1000 Cost : 0.044681 Acc 100.00%\n",
      "Epoch  410/1000 Cost : 0.043748 Acc 100.00%\n",
      "Epoch  420/1000 Cost : 0.042853 Acc 100.00%\n",
      "Epoch  430/1000 Cost : 0.041995 Acc 100.00%\n",
      "Epoch  440/1000 Cost : 0.041171 Acc 100.00%\n",
      "Epoch  450/1000 Cost : 0.040380 Acc 100.00%\n",
      "Epoch  460/1000 Cost : 0.039618 Acc 100.00%\n",
      "Epoch  470/1000 Cost : 0.038886 Acc 100.00%\n",
      "Epoch  480/1000 Cost : 0.038180 Acc 100.00%\n",
      "Epoch  490/1000 Cost : 0.037500 Acc 100.00%\n",
      "Epoch  500/1000 Cost : 0.036844 Acc 100.00%\n",
      "Epoch  510/1000 Cost : 0.036211 Acc 100.00%\n",
      "Epoch  520/1000 Cost : 0.035600 Acc 100.00%\n",
      "Epoch  530/1000 Cost : 0.035010 Acc 100.00%\n",
      "Epoch  540/1000 Cost : 0.034438 Acc 100.00%\n",
      "Epoch  550/1000 Cost : 0.033886 Acc 100.00%\n",
      "Epoch  560/1000 Cost : 0.033351 Acc 100.00%\n",
      "Epoch  570/1000 Cost : 0.032833 Acc 100.00%\n",
      "Epoch  580/1000 Cost : 0.032331 Acc 100.00%\n",
      "Epoch  590/1000 Cost : 0.031844 Acc 100.00%\n",
      "Epoch  600/1000 Cost : 0.031372 Acc 100.00%\n",
      "Epoch  610/1000 Cost : 0.030914 Acc 100.00%\n",
      "Epoch  620/1000 Cost : 0.030470 Acc 100.00%\n",
      "Epoch  630/1000 Cost : 0.030038 Acc 100.00%\n",
      "Epoch  640/1000 Cost : 0.029618 Acc 100.00%\n",
      "Epoch  650/1000 Cost : 0.029210 Acc 100.00%\n",
      "Epoch  660/1000 Cost : 0.028813 Acc 100.00%\n",
      "Epoch  670/1000 Cost : 0.028427 Acc 100.00%\n",
      "Epoch  680/1000 Cost : 0.028051 Acc 100.00%\n",
      "Epoch  690/1000 Cost : 0.027686 Acc 100.00%\n",
      "Epoch  700/1000 Cost : 0.027329 Acc 100.00%\n",
      "Epoch  710/1000 Cost : 0.026982 Acc 100.00%\n",
      "Epoch  720/1000 Cost : 0.026644 Acc 100.00%\n",
      "Epoch  730/1000 Cost : 0.026314 Acc 100.00%\n",
      "Epoch  740/1000 Cost : 0.025992 Acc 100.00%\n",
      "Epoch  750/1000 Cost : 0.025678 Acc 100.00%\n",
      "Epoch  760/1000 Cost : 0.025372 Acc 100.00%\n",
      "Epoch  770/1000 Cost : 0.025073 Acc 100.00%\n",
      "Epoch  780/1000 Cost : 0.024781 Acc 100.00%\n",
      "Epoch  790/1000 Cost : 0.024496 Acc 100.00%\n",
      "Epoch  800/1000 Cost : 0.024217 Acc 100.00%\n",
      "Epoch  810/1000 Cost : 0.023945 Acc 100.00%\n",
      "Epoch  820/1000 Cost : 0.023678 Acc 100.00%\n",
      "Epoch  830/1000 Cost : 0.023418 Acc 100.00%\n",
      "Epoch  840/1000 Cost : 0.023163 Acc 100.00%\n",
      "Epoch  850/1000 Cost : 0.022914 Acc 100.00%\n",
      "Epoch  860/1000 Cost : 0.022671 Acc 100.00%\n",
      "Epoch  870/1000 Cost : 0.022432 Acc 100.00%\n",
      "Epoch  880/1000 Cost : 0.022198 Acc 100.00%\n",
      "Epoch  890/1000 Cost : 0.021970 Acc 100.00%\n",
      "Epoch  900/1000 Cost : 0.021746 Acc 100.00%\n",
      "Epoch  910/1000 Cost : 0.021526 Acc 100.00%\n",
      "Epoch  920/1000 Cost : 0.021311 Acc 100.00%\n",
      "Epoch  930/1000 Cost : 0.021100 Acc 100.00%\n",
      "Epoch  940/1000 Cost : 0.020894 Acc 100.00%\n",
      "Epoch  950/1000 Cost : 0.020691 Acc 100.00%\n",
      "Epoch  960/1000 Cost : 0.020492 Acc 100.00%\n",
      "Epoch  970/1000 Cost : 0.020298 Acc 100.00%\n",
      "Epoch  980/1000 Cost : 0.020107 Acc 100.00%\n",
      "Epoch  990/1000 Cost : 0.019919 Acc 100.00%\n",
      "Epoch 1000/1000 Cost : 0.019735 Acc 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs + 1) :\n",
    "    h = model(X_train)\n",
    "    cost = F.binary_cross_entropy(h, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0 :\n",
    "        pred = h >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True\n",
    "        correct_pred = pred.float() == y_train # 실제값과 일치하면 True\n",
    "        acc = correct_pred.sum().item() / len(correct_pred) # 정확도 계산\n",
    "        print('Epoch {:4d}/{} Cost : {:.6f} Acc {:2.2f}%'.format(\n",
    "        epoch, epochs, cost.item(), acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07ad340d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7247e-04],\n",
       "        [3.1432e-02],\n",
       "        [3.8745e-02],\n",
       "        [9.5646e-01],\n",
       "        [9.9825e-01],\n",
       "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b9eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[3.2587, 1.5210]], requires_grad=True), Parameter containing:\n",
      "tensor([-14.5085], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e909d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d503634",
   "metadata": {},
   "source": [
    "# 클래스로 구현\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df9561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1746477e270>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b7e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__() \n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9238bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4123c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "X_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f70e025",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost : 0.653724 Accuracy 66.67%\n",
      "Epoch   10/1000 Cost : 0.357625 Accuracy 83.33%\n",
      "Epoch   20/1000 Cost : 0.428173 Accuracy 83.33%\n",
      "Epoch   30/1000 Cost : 0.340048 Accuracy 83.33%\n",
      "Epoch   40/1000 Cost : 0.286195 Accuracy 83.33%\n",
      "Epoch   50/1000 Cost : 0.238611 Accuracy 100.00%\n",
      "Epoch   60/1000 Cost : 0.196563 Accuracy 100.00%\n",
      "Epoch   70/1000 Cost : 0.165590 Accuracy 100.00%\n",
      "Epoch   80/1000 Cost : 0.148768 Accuracy 100.00%\n",
      "Epoch   90/1000 Cost : 0.138111 Accuracy 100.00%\n",
      "Epoch  100/1000 Cost : 0.129119 Accuracy 100.00%\n",
      "Epoch  110/1000 Cost : 0.121249 Accuracy 100.00%\n",
      "Epoch  120/1000 Cost : 0.114300 Accuracy 100.00%\n",
      "Epoch  130/1000 Cost : 0.108120 Accuracy 100.00%\n",
      "Epoch  140/1000 Cost : 0.102588 Accuracy 100.00%\n",
      "Epoch  150/1000 Cost : 0.097606 Accuracy 100.00%\n",
      "Epoch  160/1000 Cost : 0.093097 Accuracy 100.00%\n",
      "Epoch  170/1000 Cost : 0.088996 Accuracy 100.00%\n",
      "Epoch  180/1000 Cost : 0.085250 Accuracy 100.00%\n",
      "Epoch  190/1000 Cost : 0.081814 Accuracy 100.00%\n",
      "Epoch  200/1000 Cost : 0.078651 Accuracy 100.00%\n",
      "Epoch  210/1000 Cost : 0.075730 Accuracy 100.00%\n",
      "Epoch  220/1000 Cost : 0.073023 Accuracy 100.00%\n",
      "Epoch  230/1000 Cost : 0.070507 Accuracy 100.00%\n",
      "Epoch  240/1000 Cost : 0.068164 Accuracy 100.00%\n",
      "Epoch  250/1000 Cost : 0.065975 Accuracy 100.00%\n",
      "Epoch  260/1000 Cost : 0.063925 Accuracy 100.00%\n",
      "Epoch  270/1000 Cost : 0.062002 Accuracy 100.00%\n",
      "Epoch  280/1000 Cost : 0.060194 Accuracy 100.00%\n",
      "Epoch  290/1000 Cost : 0.058491 Accuracy 100.00%\n",
      "Epoch  300/1000 Cost : 0.056883 Accuracy 100.00%\n",
      "Epoch  310/1000 Cost : 0.055364 Accuracy 100.00%\n",
      "Epoch  320/1000 Cost : 0.053925 Accuracy 100.00%\n",
      "Epoch  330/1000 Cost : 0.052561 Accuracy 100.00%\n",
      "Epoch  340/1000 Cost : 0.051266 Accuracy 100.00%\n",
      "Epoch  350/1000 Cost : 0.050034 Accuracy 100.00%\n",
      "Epoch  360/1000 Cost : 0.048861 Accuracy 100.00%\n",
      "Epoch  370/1000 Cost : 0.047743 Accuracy 100.00%\n",
      "Epoch  380/1000 Cost : 0.046676 Accuracy 100.00%\n",
      "Epoch  390/1000 Cost : 0.045656 Accuracy 100.00%\n",
      "Epoch  400/1000 Cost : 0.044681 Accuracy 100.00%\n",
      "Epoch  410/1000 Cost : 0.043748 Accuracy 100.00%\n",
      "Epoch  420/1000 Cost : 0.042853 Accuracy 100.00%\n",
      "Epoch  430/1000 Cost : 0.041995 Accuracy 100.00%\n",
      "Epoch  440/1000 Cost : 0.041171 Accuracy 100.00%\n",
      "Epoch  450/1000 Cost : 0.040380 Accuracy 100.00%\n",
      "Epoch  460/1000 Cost : 0.039618 Accuracy 100.00%\n",
      "Epoch  470/1000 Cost : 0.038886 Accuracy 100.00%\n",
      "Epoch  480/1000 Cost : 0.038180 Accuracy 100.00%\n",
      "Epoch  490/1000 Cost : 0.037500 Accuracy 100.00%\n",
      "Epoch  500/1000 Cost : 0.036844 Accuracy 100.00%\n",
      "Epoch  510/1000 Cost : 0.036211 Accuracy 100.00%\n",
      "Epoch  520/1000 Cost : 0.035600 Accuracy 100.00%\n",
      "Epoch  530/1000 Cost : 0.035010 Accuracy 100.00%\n",
      "Epoch  540/1000 Cost : 0.034438 Accuracy 100.00%\n",
      "Epoch  550/1000 Cost : 0.033886 Accuracy 100.00%\n",
      "Epoch  560/1000 Cost : 0.033351 Accuracy 100.00%\n",
      "Epoch  570/1000 Cost : 0.032833 Accuracy 100.00%\n",
      "Epoch  580/1000 Cost : 0.032331 Accuracy 100.00%\n",
      "Epoch  590/1000 Cost : 0.031844 Accuracy 100.00%\n",
      "Epoch  600/1000 Cost : 0.031372 Accuracy 100.00%\n",
      "Epoch  610/1000 Cost : 0.030914 Accuracy 100.00%\n",
      "Epoch  620/1000 Cost : 0.030470 Accuracy 100.00%\n",
      "Epoch  630/1000 Cost : 0.030038 Accuracy 100.00%\n",
      "Epoch  640/1000 Cost : 0.029618 Accuracy 100.00%\n",
      "Epoch  650/1000 Cost : 0.029210 Accuracy 100.00%\n",
      "Epoch  660/1000 Cost : 0.028813 Accuracy 100.00%\n",
      "Epoch  670/1000 Cost : 0.028427 Accuracy 100.00%\n",
      "Epoch  680/1000 Cost : 0.028051 Accuracy 100.00%\n",
      "Epoch  690/1000 Cost : 0.027686 Accuracy 100.00%\n",
      "Epoch  700/1000 Cost : 0.027329 Accuracy 100.00%\n",
      "Epoch  710/1000 Cost : 0.026982 Accuracy 100.00%\n",
      "Epoch  720/1000 Cost : 0.026644 Accuracy 100.00%\n",
      "Epoch  730/1000 Cost : 0.026314 Accuracy 100.00%\n",
      "Epoch  740/1000 Cost : 0.025992 Accuracy 100.00%\n",
      "Epoch  750/1000 Cost : 0.025678 Accuracy 100.00%\n",
      "Epoch  760/1000 Cost : 0.025372 Accuracy 100.00%\n",
      "Epoch  770/1000 Cost : 0.025073 Accuracy 100.00%\n",
      "Epoch  780/1000 Cost : 0.024781 Accuracy 100.00%\n",
      "Epoch  790/1000 Cost : 0.024496 Accuracy 100.00%\n",
      "Epoch  800/1000 Cost : 0.024217 Accuracy 100.00%\n",
      "Epoch  810/1000 Cost : 0.023945 Accuracy 100.00%\n",
      "Epoch  820/1000 Cost : 0.023678 Accuracy 100.00%\n",
      "Epoch  830/1000 Cost : 0.023418 Accuracy 100.00%\n",
      "Epoch  840/1000 Cost : 0.023163 Accuracy 100.00%\n",
      "Epoch  850/1000 Cost : 0.022914 Accuracy 100.00%\n",
      "Epoch  860/1000 Cost : 0.022671 Accuracy 100.00%\n",
      "Epoch  870/1000 Cost : 0.022432 Accuracy 100.00%\n",
      "Epoch  880/1000 Cost : 0.022198 Accuracy 100.00%\n",
      "Epoch  890/1000 Cost : 0.021970 Accuracy 100.00%\n",
      "Epoch  900/1000 Cost : 0.021746 Accuracy 100.00%\n",
      "Epoch  910/1000 Cost : 0.021526 Accuracy 100.00%\n",
      "Epoch  920/1000 Cost : 0.021311 Accuracy 100.00%\n",
      "Epoch  930/1000 Cost : 0.021100 Accuracy 100.00%\n",
      "Epoch  940/1000 Cost : 0.020894 Accuracy 100.00%\n",
      "Epoch  950/1000 Cost : 0.020691 Accuracy 100.00%\n",
      "Epoch  960/1000 Cost : 0.020492 Accuracy 100.00%\n",
      "Epoch  970/1000 Cost : 0.020298 Accuracy 100.00%\n",
      "Epoch  980/1000 Cost : 0.020107 Accuracy 100.00%\n",
      "Epoch  990/1000 Cost : 0.019919 Accuracy 100.00%\n",
      "Epoch 1000/1000 Cost : 0.019735 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs+1) :\n",
    "    h = model(X_train)\n",
    "    cost = F.binary_cross_entropy(h, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0 :\n",
    "        p = h >= torch.FloatTensor([0.5])  # 예측값이 0.5 를 넘어야 True\n",
    "        corr_pred = p.float() == y_train  # 실제값이 일치하는 경우만 True\n",
    "        acc = corr_pred.sum().item() / len(corr_pred)\n",
    "        print('Epoch {:4d}/{} Cost : {:.6f} Accuracy {:2.2f}%'.format(\n",
    "        epoch, epochs, cost.item(), acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db9e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62062f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847da05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeseul",
   "language": "python",
   "name": "yeseul"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
